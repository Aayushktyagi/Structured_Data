{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Heart_disease_classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aayushktyagi/Structured_Data/blob/master/Heart_disease_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_k0g3WzKsLat",
        "colab_type": "text"
      },
      "source": [
        "**Classification problem using heart disease dataset.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N4wUVbzqqu5",
        "colab_type": "code",
        "outputId": "ddad592e-3c8a-45dd-dc4d-5fe368865ab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "!pip3 install tensorflow==2.0.0-beta1\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow import feature_column\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "tf.__version__\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.0.0-beta1 in /usr/local/lib/python3.6/dist-packages (2.0.0b1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (3.7.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.0.8)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.2.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.33.6)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190604,>=1.14.0a20190603 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.14.0a20190603)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.11.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.14.0.dev2019060501)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.8.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.16.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.1.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0-beta1) (41.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-beta1) (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (0.15.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (3.1.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0-beta1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqhVQ25WFzsT",
        "colab_type": "text"
      },
      "source": [
        "**Load Dataset and Split into train and test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKqqZlTMEoiA",
        "colab_type": "code",
        "outputId": "9f87cea5-4a91-4dff-d6e0-ab6d44aa3d2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "url = 'https://storage.googleapis.com/applied-dl/heart.csv'\n",
        "dataframe = pd.read_csv(url)\n",
        "dataframe.head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>fixed</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>160</td>\n",
              "      <td>286</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>108</td>\n",
              "      <td>1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>normal</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>120</td>\n",
              "      <td>229</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "      <td>2.6</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>reversible</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  sex  cp  trestbps  chol  ...  oldpeak  slope  ca        thal  target\n",
              "0   63    1   1       145   233  ...      2.3      3   0       fixed       0\n",
              "1   67    1   4       160   286  ...      1.5      2   3      normal       1\n",
              "2   67    1   4       120   229  ...      2.6      2   2  reversible       0\n",
              "3   37    1   3       130   250  ...      3.5      3   0      normal       0\n",
              "4   41    0   2       130   204  ...      1.4      1   0      normal       0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl6OPymjFxiE",
        "colab_type": "code",
        "outputId": "88397beb-2271-42b1-bc14-f3859b846fbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "#split dataset\n",
        "train,test = train_test_split(dataframe,test_size = 0.2)\n",
        "train,val = train_test_split(train, test_size = 0.2)\n",
        "print(\"Training examples\",len(train))\n",
        "print(\"Validation examples\",len(val))\n",
        "print(\"test examples\",len(test))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training examples 193\n",
            "Validation examples 49\n",
            "test examples 61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHxq2I4bKBmr",
        "colab_type": "text"
      },
      "source": [
        "**Creating tf.data from pandas Dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Mnwe5mlKQqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def df_to_dataset(dataframe,shuffle=True,batch_size = 32):\n",
        "  dataframe = dataframe.copy()\n",
        "  labels = dataframe.pop(\"target\")\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe),labels))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "  ds = ds.batch(batch_size)\n",
        "  return ds \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzBOs2q-M_C6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Testing df to dataset conversion\n",
        "batch_size = 5\n",
        "ds_train = df_to_dataset(train ,batch_size = batch_size)\n",
        "ds_val = df_to_dataset(val,shuffle =False , batch_size = batch_size)\n",
        "ds_test = df_to_dataset(test , shuffle =False , batch_size = batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ni5w3v7MN1QM",
        "colab_type": "code",
        "outputId": "1bd10c77-8fe3-4e94-e0e1-52c29168c926",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "for feature_batch , label_batch in ds_train.take(1):\n",
        "  print(\"Features:\",list(feature_batch.keys()))\n",
        "  print(\"batch of ages\",feature_batch['age'])\n",
        "  print(\"batch of labels\",label_batch)\n",
        "  print(\"Feature batch\", feature_batch)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features: ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']\n",
            "batch of ages tf.Tensor([52 51 57 77 71], shape=(5,), dtype=int32)\n",
            "batch of labels tf.Tensor([0 0 0 1 0], shape=(5,), dtype=int32)\n",
            "Feature batch {'age': <tf.Tensor: id=69, shape=(5,), dtype=int32, numpy=array([52, 51, 57, 77, 71], dtype=int32)>, 'sex': <tf.Tensor: id=77, shape=(5,), dtype=int32, numpy=array([1, 0, 1, 1, 0], dtype=int32)>, 'cp': <tf.Tensor: id=72, shape=(5,), dtype=int32, numpy=array([1, 3, 3, 4, 3], dtype=int32)>, 'trestbps': <tf.Tensor: id=81, shape=(5,), dtype=int32, numpy=array([152, 120, 128, 125, 110], dtype=int32)>, 'chol': <tf.Tensor: id=71, shape=(5,), dtype=int32, numpy=array([298, 295, 229, 304, 265], dtype=int32)>, 'fbs': <tf.Tensor: id=74, shape=(5,), dtype=int32, numpy=array([1, 0, 0, 0, 1], dtype=int32)>, 'restecg': <tf.Tensor: id=76, shape=(5,), dtype=int32, numpy=array([0, 2, 2, 2, 2], dtype=int32)>, 'thalach': <tf.Tensor: id=80, shape=(5,), dtype=int32, numpy=array([178, 157, 150, 162, 130], dtype=int32)>, 'exang': <tf.Tensor: id=73, shape=(5,), dtype=int32, numpy=array([0, 0, 0, 1, 0], dtype=int32)>, 'oldpeak': <tf.Tensor: id=75, shape=(5,), dtype=float32, numpy=array([1.2, 0.6, 0.4, 0. , 0. ], dtype=float32)>, 'slope': <tf.Tensor: id=78, shape=(5,), dtype=int32, numpy=array([2, 1, 2, 1, 1], dtype=int32)>, 'ca': <tf.Tensor: id=70, shape=(5,), dtype=int32, numpy=array([0, 0, 1, 3, 1], dtype=int32)>, 'thal': <tf.Tensor: id=79, shape=(5,), dtype=string, numpy=\n",
            "array([b'reversible', b'normal', b'reversible', b'normal', b'normal'],\n",
            "      dtype=object)>}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPFPvPUDdLlI",
        "colab_type": "text"
      },
      "source": [
        "**Demonstrate Several type of feature column**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fwtg8duHdDbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#example feature column\n",
        "example_batch = next(iter(ds_train))[0]\n",
        "\n",
        "#method to create feature column\n",
        "def demo(feature_column):\n",
        "  feature_layer = layers.DenseFeatures(feature_column)\n",
        "  print(feature_layer(example_batch).numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GILR4cbGfkw2",
        "colab_type": "text"
      },
      "source": [
        "**Numeric column**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuTQeBXlfkEH",
        "colab_type": "code",
        "outputId": "a2d63bc7-19d7-45e4-a5bd-84eb1d5cfb1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "age = feature_column.numeric_column(\"age\")\n",
        "demo(age)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[52.]\n",
            " [51.]\n",
            " [57.]\n",
            " [77.]\n",
            " [71.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rGHwoJwiZF0",
        "colab_type": "text"
      },
      "source": [
        "**Bucketized column**\n",
        "\n",
        "If you don't want to feed a number directly into a model but instead split the value into different categories based on numeric ranges.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCU-Yk6KizHe",
        "colab_type": "code",
        "outputId": "e27eacc5-7696-47e3-9599-f9fd16fbbdc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "age_bucket = feature_column.bucketized_column(age , boundaries=[18,25,30,35,40,45,55,60,65])\n",
        "demo(age_bucket)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQ0mpJBRj34W",
        "colab_type": "text"
      },
      "source": [
        "**Categorical columns**\n",
        "\n",
        "In datasets , columns contains values represented as strings. We cannot feed strings directly to a model. Instead we first map them to numeric values. Categorical vocabulary columns provide a way to represent strings to one-hot vector.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvpuLBb6lCMV",
        "colab_type": "code",
        "outputId": "ccd4326e-c2e9-40c1-a33a-de94f3072326",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "thal = feature_column.categorical_column_with_vocabulary_list(\n",
        "      'thal',['fixed','normal','reversible'])\n",
        "thal_one_hot = feature_column.indicator_column(thal)\n",
        "demo(thal_one_hot)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:2655: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4215: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4270: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itY9aqIwnVRb",
        "colab_type": "text"
      },
      "source": [
        "**Embedding Column**\n",
        "\n",
        "Suppose instead of having few possible strings, we have thousands values per category.So it become infeasible to train a neural network using one hot encoding. We can represent columns with much lower dimension where each cell contains any number not just 0 or 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XY4wn4kDn6DD",
        "colab_type": "code",
        "outputId": "ee27e70f-2592-4049-8d3a-289391fbd1fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "thal_embedding = feature_column.embedding_column(thal,dimension=8)\n",
        "demo(thal_embedding)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.43031818 -0.5140477  -0.14765057  0.5500358   0.25458595  0.4369187\n",
            "   0.6556285   0.59381485]\n",
            " [-0.20032851 -0.14532904 -0.13461508  0.18059397  0.51310056 -0.19209644\n",
            "   0.2993331   0.23008475]\n",
            " [-0.43031818 -0.5140477  -0.14765057  0.5500358   0.25458595  0.4369187\n",
            "   0.6556285   0.59381485]\n",
            " [-0.20032851 -0.14532904 -0.13461508  0.18059397  0.51310056 -0.19209644\n",
            "   0.2993331   0.23008475]\n",
            " [-0.20032851 -0.14532904 -0.13461508  0.18059397  0.51310056 -0.19209644\n",
            "   0.2993331   0.23008475]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Dnry7TkpT7o",
        "colab_type": "text"
      },
      "source": [
        "**Cross Feature columns**\n",
        "Combining features into single feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDygVWvvpc8H",
        "colab_type": "code",
        "outputId": "0ef74f98-50b1-44f9-e359-43c0375be2d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "crossed_feature = feature_column.crossed_column([age_bucket,thal],hash_bucket_size=1000)\n",
        "demo(feature_column.indicator_column(crossed_feature))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/feature_column/feature_column_v2.py:4270: CrossedColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oK7sooRkqHDZ",
        "colab_type": "text"
      },
      "source": [
        "**Choosing feature**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1_pbqeoqM8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_columns = []\n",
        "\n",
        "# numeric cols\n",
        "for header in ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'slope', 'ca']:\n",
        "  feature_columns.append(feature_column.numeric_column(header))\n",
        "\n",
        "# bucketized cols\n",
        "age_buckets = feature_column.bucketized_column(age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\n",
        "feature_columns.append(age_buckets)\n",
        "\n",
        "# indicator cols\n",
        "thal = feature_column.categorical_column_with_vocabulary_list(\n",
        "      'thal', ['fixed', 'normal', 'reversible'])\n",
        "thal_one_hot = feature_column.indicator_column(thal)\n",
        "feature_columns.append(thal_one_hot)\n",
        "\n",
        "# embedding cols\n",
        "thal_embedding = feature_column.embedding_column(thal, dimension=8)\n",
        "feature_columns.append(thal_embedding)\n",
        "\n",
        "# crossed cols\n",
        "# crossed_feature = feature_column.crossed_column([age_buckets, thal], hash_bucket_size=1000)\n",
        "# crossed_feature = feature_column.indicator_column(crossed_feature)\n",
        "# feature_columns.append(crossed_feature)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fgwkDqhsxsN",
        "colab_type": "text"
      },
      "source": [
        "**Create feature layer**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1o-DA-mvs123",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CiLtZX3tC-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "ds_train = df_to_dataset(train ,batch_size = batch_size)\n",
        "ds_val = df_to_dataset(val,shuffle =False , batch_size = batch_size)\n",
        "ds_test = df_to_dataset(test , shuffle =False , batch_size = batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTGtUUgWtSYU",
        "colab_type": "text"
      },
      "source": [
        "**Create , comple and Train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEXs_yKPtX86",
        "colab_type": "code",
        "outputId": "4a5fc277-b2d2-485e-8494-9203ef5a7645",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "model = keras.Sequential([\n",
        "        feature_layer,\n",
        "        layers.Dense(128,activation='relu'),\n",
        "        layers.Dense(128,activation='relu'),\n",
        "        layers.Dense(1,activation='sigmoid')\n",
        "])\n",
        "model.compile(loss = 'binary_crossentropy',\n",
        "              optimizer = 'adam',\n",
        "              metrics = ['accuracy'])\n",
        "model.fit(ds_train,\n",
        "          validation_data =ds_val,\n",
        "          epochs = 10)\n",
        "\n",
        "loss , acc = model.evaluate(ds_test)\n",
        "print(\"Accuracy:{}\".format(acc))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "7/7 [==============================] - 2s 273ms/step - loss: 1.7170 - accuracy: 0.5936 - val_loss: 0.7550 - val_accuracy: 0.5918\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.7331 - accuracy: 0.6849 - val_loss: 0.6821 - val_accuracy: 0.6531\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5851 - accuracy: 0.7145 - val_loss: 0.7099 - val_accuracy: 0.7347\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.4596 - accuracy: 0.7565 - val_loss: 1.0326 - val_accuracy: 0.6735\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5245 - accuracy: 0.7433 - val_loss: 1.3503 - val_accuracy: 0.6735\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6035 - accuracy: 0.7231 - val_loss: 1.7397 - val_accuracy: 0.6735\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.7760 - accuracy: 0.6939 - val_loss: 1.7682 - val_accuracy: 0.6735\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.9283 - accuracy: 0.7026 - val_loss: 1.1853 - val_accuracy: 0.7347\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.8144 - accuracy: 0.7015 - val_loss: 0.7293 - val_accuracy: 0.6735\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6400 - accuracy: 0.7659 - val_loss: 0.7329 - val_accuracy: 0.6122\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 1.3673 - accuracy: 0.5902\n",
            "Accuracy:0.5901639461517334\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}